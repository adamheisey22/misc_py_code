{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f70897-ffb4-4c5d-b9f0-6b16ebf522bd",
   "metadata": {},
   "source": [
    "# Exploration of World Co2 Emissions \n",
    "## Applications of distributions developed by Kuznets, Lorenz, and Gini \n",
    "### Python Course Final Project | Adam Russel Heisey | 04/27/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d38ca-0141-4798-a516-ef9cfb8d7fde",
   "metadata": {},
   "source": [
    "### STEP 1: IMPORT LIBRARIES, PACKAGES, AND FUNCTIONS FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcf0dbd-6978-4697-a592-e6480c252804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log as ln\n",
    "import requests\n",
    "from linearmodels import PanelOLS\n",
    "from linearmodels import RandomEffects\n",
    "import statsmodels.api as sm\n",
    "from numpy import log as ln\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a2ee7-8ae1-468c-be57-3837ac4da3ec",
   "metadata": {},
   "source": [
    "#### -> Following the tutorial cited below, I adapted the following function to define downloading data from a url link, which allows me to download a csv file directly from a website link directly into my directory under a name I assign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17141d-93c1-44df-84ca-8aadb4c27b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename=' '):\n",
    "    try:\n",
    "        if filename:\n",
    "            pass\n",
    "        else:\n",
    "            filename = req.url[downloadURL.rfind('/')+1:]\n",
    "\n",
    "        with requests.get(url) as req:\n",
    "            with open(filename, 'wb') as f:\n",
    "                for chunk in req.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            return filename\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "#works cited: tutorial on creating this code-->  https://learndataanalysis.org/create-a-python-program-to-download-file-from-the-web-python-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399271c-fa87-4da5-8e5f-8a7fb580f8cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 2: DATA SOURCE AND DOWNLOAD\n",
    "\n",
    "#### -> Using Kaggle.com, I found a website called Our World in Data (link below), which has compiled datasets of information across numerous sectors. Because I am interested in exploring Co2 emissions around the world, I chose to download their complete Co2 dataset. The link to the dataset and the codebook are found at thier github page, which I sited below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bef72-6908-42f3-8e88-39bddc2bf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.csv' #copied the url for the complete csv dataset and named the link address 'x'\n",
    "download_file(x, 'co2.csv') #used the function above to download the csv file to my workspace folder and named the file 'co2.csv'\n",
    "\n",
    "#works cited: co2 dataset github page -> https://github.com/owid/co2-data\n",
    "#works cited: Our world in Data website-> https://ourworldindata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77142a8-ebb3-45c9-bca2-d187a3667b14",
   "metadata": {},
   "source": [
    "#### -> Using the PANDAS package, I read the csv file and named the dataframe 'co' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a040695-35d2-4386-b781-ce80e7906b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = pd.read_csv('co2.csv') #read csv file and named pandas dataframe 'co'\n",
    "print(co.head(5)) #to explore the first 5 rows\n",
    "print(co.info()) #to see a list of the columns, index, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566263c-394b-41b4-9a50-976e5eae5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "co.isnull().sum() #checking DF for sum of null values for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3130d2-abb4-4c8d-ad6d-8da7c96673ce",
   "metadata": {},
   "source": [
    "#### -> From above, I can see that this dataset has 60 variable columns, and 25989 rows that includes time-series data for most (not all) countries in the world. For panel data analysis the data would be most helpful to be organized by time ('year') and country ('iso code'). Also, I can see that there are a lot of missing values, which indicates an unbalanced/incomplete world dataset.Using PANDAS, I re-read the csv file and indexed the df by the column year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178a165-9b6f-4547-b27f-0f42bc660c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = pd.read_csv('co2.csv', parse_dates = ['year'], index_col = 'year') #parse dates pulls the year and puts it into the datetime helpful for indexing on year column. \n",
    "print(co.head(5)) #print first 5 rows\n",
    "print(co.tail(5)) #print last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bef30-9d51-4d1a-a437-69e28b55d86b",
   "metadata": {},
   "source": [
    "### STEP 3: DEFINE OBJECTIVES\n",
    "#### -> Based on the preliminary analysis of this data source, because there are a lot of missing values (years) for countries and because there are a lot of columns, I defined some goals/objectives:\n",
    "\n",
    "##### 1) Reshape dataset and clean missing data for Panal Data analysis--multi level country (ID) by year for 2010 to 2019 (with the assumption that there are more data rows post 2010 and missing data for countries in 2020-either not published or missing bc COVID-)\n",
    "\n",
    "##### 2) Run Fixed Effects Panel regression to test Kuznets Curve relationship--as countries develop(grow gdp) they initally produce more Co2, but decrease co2 emissions as they develop.\n",
    "\n",
    "###### Simple model: co2 = gdp + gdp^2 + energy consumption + e\n",
    "\n",
    "##### 3) Take begining and end (2010 and 2019) cross-sections and compare world inequality of Co2 emission with Gini coefficent/lorenz curves\n",
    "\n",
    "##### 4) Use plots to create data visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0df089-f177-4f42-aa16-ed1232c88338",
   "metadata": {},
   "source": [
    "#### -> 1) Reshape dataset for Panel Data regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab010fd6-8ae1-4e90-95df-9b4d50c7e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "co1 = co.loc[:,['iso_code','country', 'co2_per_capita','energy_per_capita', 'population', 'gdp' ]] # create new df called 'co1' from 'co' df with 6 colums\n",
    "\n",
    "startDate = '2010-01-01' #define start date for time series\n",
    "endDate = '2019-01-01' #define end date for time series--this is exclusive\n",
    "\n",
    "# Create columns for year, month, day to help create date as datetype datatype\n",
    "co1['Year'] = co1.index.astype(str).str[:4]\n",
    "co1['Month'] = 1 \n",
    "co1['Day'] = 1\n",
    "co1['Date'] = pd.to_datetime(co1[['Year','Month','Day']])\n",
    "\n",
    "#set index to Date and sort each counry by index, which is year. This should show each country in starting in 2010. \n",
    "co1.set_index('Date',drop=True,inplace=True)\n",
    "co1.sort_index(inplace=True)\n",
    "\n",
    "#Overwrite df 'co1' with new 'co1' based on the start date and end date from above. \n",
    "co1 = co1[startDate:endDate]\n",
    "co1 = co1.iloc[:,:]\n",
    "co1['Date'] = co1.index\n",
    "\n",
    "print(co1.head(5)) #print first 5 rows\n",
    "print(co1.tail(5)) #print last 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3e955-6f7c-4f6a-9637-fe7ca04a0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the pandas multi index I structured the 'co1' df to ogranize the time series by iso country and year and named the columns ID and year\n",
    "co1.index = pd.MultiIndex.from_arrays(co1[['iso_code', 'Date']].values.T, names=['ID', 'year'])\n",
    "\n",
    "co1.sort_index(inplace=True) #sorts both indeces the by ascending (default) in years and countries--starting with 'A' and 2010 in my df\n",
    "\n",
    "mi = co1.set_index([\"iso_code\", \"Date\"]) #created a new df for my panal analysis called 'mi' (multi-index). This pulls the columns and indexes first by country code then by year\n",
    "\n",
    "print(mi.head(5))#print first 5 rows\n",
    "print(mi.tail(5))#print last 5 rows\n",
    "\n",
    "\n",
    "#works cited: Data formats and estimation for Panel Data -> https://bashtage.github.io/linearmodels/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3904ca-31b5-478f-bbb6-d589c4924e52",
   "metadata": {},
   "source": [
    "#### Missing data-> Bc my dataset has a lot of missing data, I decided to only analyze countries that had non-missing values for each of the columns. This results in an unbalanced dataset with countries able to be fall in and out depending on the availability of data for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186f5fd-31a4-4aaf-9c08-e7314e4346ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mi.dropna() #drops rows with missing values. Limits by data to only include countries that have non-missing data for each column. \n",
    "\n",
    "# convert the variables from level to log form to allow for easier interpretation of results:\n",
    "mi['gdp_per_capita'] = (mi['gdp']) / (mi['population']) #creates a new column based on existing columns --gdp per capita\n",
    "mi['gpd_per_capita_squ'] = (mi['gdp_per_capita'])*(mi['gdp_per_capita']) #calculates and add new column log of gdp per capita squared\n",
    "mi['ln_gdp_per_capita'] = ln(mi['gdp_per_capita']) #new column that is the log of gdp per capita\n",
    "mi['ln_gpd_per_capita_squ'] = (mi['ln_gdp_per_capita'])*(mi['ln_gdp_per_capita']) #calculates and add new column log of gdp per capita squared\n",
    "mi['ln_co2_per_capita'] = ln(mi['co2_per_capita']) #new column that is the log of co2 per capita\n",
    "mi['ln_energy_per_capita'] = ln(mi['energy_per_capita']) #new column that is the log of energy per capita\n",
    "\n",
    "print(mi.head(5)) #print first 5 rows\n",
    "print(mi.tail(5)) #print last 5 rows\n",
    "\n",
    "print(mi.info()) #prints info for panel df 'mi'\n",
    "\n",
    "print(mi['country'].unique()) #prints the list of unique countries in my analysis\n",
    "print(mi['country'].nunique()) #prints the number of unique countreis in my analysis\n",
    "\n",
    "mi.to_csv('Co2Paneldataformat.csv') #saves df to csv\n",
    "mi.to_stata('Co2Paneldataformat.dta') #saves df to stata data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49775d8-86d6-4701-addd-94136cfbbe5e",
   "metadata": {},
   "source": [
    "#### -> 2) Run Panel regression with FIXED EFFECTS (entity effects in python) with Robust standard errors to account for heteroskedacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9e00c-5965-4710-8815-bdb70ab43b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = (mi.loc[:,['ln_co2_per_capita']]) #set my dependent variable--log of co2 emissions\n",
    "Xs = sm.tools.tools.add_constant(mi.loc[:,['ln_energy_per_capita', 'ln_gdp_per_capita', 'ln_gpd_per_capita_squ']]) # my logged independent variables adding a constant term\n",
    "\n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(Y, Xs, entity_effects = True) #add fixed effects to account for unobservable, unit specific, and time invariant effects\n",
    "fe_res = model_fe.fit(cov_type = \"robust\") #add robust standard errors to correct for heteroskedacity\n",
    "#print results\n",
    "print(fe_res)\n",
    "\n",
    "#works cited: help with panel regression in python -> https://towardsdatascience.com/a-guide-to-panel-data-regression-theoretics-and-implementation-with-python-4c84c5055cf8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bb0eb-3eef-457a-8500-51ffcbcc10f4",
   "metadata": {},
   "source": [
    "# RESULTS:\n",
    "\n",
    "#### From the regression results above, we can see that this model has statistically significant coefficents with p-values (0.0000) and and overall high between and overall R-squared (0.92), which suggest that this model accounts for 92% of the variance within panel units; making this a relatively good model. \n",
    "\n",
    "#### The results, with the postive coefficents for gdp and negative for gdp squared, support the inverted U-shape Kuznets curve hythopthesis as related to environmental degration and co2 emissions:  That co2 emissions increases with econonomic growth (increased gdp) then reach some optimal level, and then co2 emissions start to fall(as countries start to move away from manufacturing or start to regulate co2 emissions). Below is a graphical representation with a few outliers at the top, but you can almost visualize the inverted U-shape. I will attempt to show this relationship using some cross-sections of specific years. \n",
    "\n",
    "#### The coefficient on energy per capita suggest a 1% increase in energy consumption per capita results in a 0.76% increase in co2 emissions per capita, holding all else equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef34862-ef23-4386-a8c7-6030cdb1151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.regplot(x=\"gdp_per_capita\", y=\"co2_per_capita\", data=mi, x_estimator=np.mean, logx=True) #plots the regression of gdp per capita and co2 emissions per capita.\n",
    "\n",
    "# Note: it is important to note, this is not a plot of the panel data residuals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64805fcd-a21d-4353-8c05-a2d78aaa8afa",
   "metadata": {},
   "source": [
    "#### -The Theorectial Framework-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892002e-c150-403e-ba85-6b5d094958c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 100 equally spaced points between -10 and 10\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Basic theoretical relationship--inverse U\n",
    "y = x - x**2 \n",
    "\n",
    "with plt.style.context('seaborn-dark-palette'):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"ECONOMIC GROWTH (gdp per capita\")\n",
    "    plt.ylabel(\"ENVIRONMENTAL POLLUTION (co2 per capita)\")\n",
    "    plt.title(\"ENVIRONMENTAL KUZNETS CURVE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dded02-ab1d-4699-a7fa-14c588451462",
   "metadata": {},
   "source": [
    "#### -> 3) Estimating Gini coefficents for Co2 inequality with Lorenz curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e085f-c306-4b77-b9f9-1602a77c73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi['Year'].unique() #check to see how many complete years I have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d4f12-1d8e-4f56-be59-4b59a4a18ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect cross-sections of co2 data for 2010 and save df as 'coy10'\n",
    "coy10 = mi.loc[(mi['Year'] == '2010')]\n",
    "coy10 = coy10.loc[:,['country', 'co2_per_capita', 'gdp_per_capita']]\n",
    "#coy10\n",
    "\n",
    "#collect cross-sections of co2 data for 2018 and save df as 'coy18'\n",
    "coy18 = mi.loc[(mi['Year'] == '2018')]\n",
    "coy18 = coy18.loc[:,['country', 'co2_per_capita', 'gdp_per_capita']]\n",
    "#coy18\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bf403-a431-4ec4-86cb-3080c32fd9e4",
   "metadata": {},
   "source": [
    "#### -> Following the link cited below, I adapted the following function to calculate the Gini Coefficent, which is a measure of statistical dispersion intended to represent inequality of distributions in a population group. I adapted its use, which is usually applied to wealth or income, to represent the inequality of co2 emissions across 165 countries in the world in 2010 and the same countries in 2018. I found several authors/adaptations of the gini coeffiecnt, but the one below allows for easy graphing/visualizations because it not only calculates the Gini coefficient, but it also returns the differnent areas under the curve, which makes plotting the results more efficient. \n",
    "\n",
    "#### -> Here is a link to more information about the Gini Coefficient: https://en.wikipedia.org/wiki/Gini_coefficient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75666bf0-bec9-4c37-9851-05847fa40f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(v):\n",
    "    bins = np.linspace(0., 100., 10)\n",
    "    total = float(np.sum(v))\n",
    "    yvals = []\n",
    "    for b in bins:\n",
    "        bin_vals = v[v <= np.percentile(v, b)]\n",
    "        bin_fraction = (np.sum(bin_vals) / total) * 100.0\n",
    "        yvals.append(bin_fraction)\n",
    "    # perfect equality area\n",
    "    pe_area = np.trapz(bins, x=bins)\n",
    "    # lorenz area\n",
    "    lorenz_area = np.trapz(yvals, x=bins)\n",
    "    gini_val = (pe_area - lorenz_area) / float(pe_area)\n",
    "    return bins, yvals, gini_val\n",
    "\n",
    "#Works cited: Gini Coefficent assistance (author unknown) -> https://stackoverflow.com/questions/39512260/calculating-gini-coefficient-in-python-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7d5b6-ff55-4c41-8cf5-dcac7bd593b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = coy10['co2_per_capita'].values #returns the vector values of co2 emissions in the 2010 cross section\n",
    "z = coy18['co2_per_capita'].values #returns the vector values of co2 emissions in the 2018 cross section\n",
    "vbins, vresult, vgini_val = G(v) #calculates the Gini for 2010 vector\n",
    "zbins, zresult, zgini_val = G(z) #calculates the Gini for 2018 vector\n",
    "with plt.style.context('seaborn-dark-palette'): #changed the style, just for fun\n",
    "    plt.figure()\n",
    "    plt.plot(vbins, vresult, label=\"2010 GINI: %.4f\" %(vgini_val)) #plots the results for 2010\n",
    "    plt.plot(vbins, vbins, '--', label=\"perfect equality\") #draws teh perfect equality line\n",
    "    plt.plot(zbins, zresult, label=\"2018 GINI: %.4f\" %(zgini_val)) #overlays and plots the results for 2018\n",
    "\n",
    "    #below I added axis and graph titles/labesl\n",
    "    plt.xlabel(\"Fraction of sample population\")\n",
    "    plt.ylabel(\"Fraction of Co2 Emissions\")\n",
    "    plt.title(\"LORENZ CURVES OF CO2 EMISSIONS DISTRIBUTIONS 2010 VS 2018\")\n",
    "    plt.title(\"LORENZ CURVES OF CO2 EMISSIONS DISTRIBUTIONS 2010 VS 2018\")\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#added histogram of co2 emissions to get the counts of countries in the co2 per capita bins (10)\n",
    "with plt.style.context('seaborn-dark-palette'): #changed the style, just for fun\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(v, bins=10, label=True)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.hist(z, bins=10)\n",
    "    plt.xlabel(\"Co2 emission per Capita 2010(top) vs. 2018(bottom)\")\n",
    "    plt.ylabel(\"Number of Countries\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3007a4-e3a5-421f-af7d-dd3311368409",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "#### From the Lorenz curves, and the Gini coefficients calcualted/represented above, we can see that for the population of 165 countries in my sample, the distribution of C02 emissions has decreased by  ~2.17 percentage points, which is a 3.75% decrease in the inequality of Co2 emissions across the 165 countries. Perfect equality is represted with a Gini of 0 and Perfect Inequality with a Gini of 1. Although co2 emissions is becoming more equal, a Gini greater than .50 still represents high inequality, which means that there are higher levels of co2 emissions per capita by a fewer number of countries.This is represented in the histogram above; We can see that there is a higher proportion of countries in the the lower levels of co2 emissions per capital bins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b98e9-c86a-48ae-9dcd-1b3c7c276e2f",
   "metadata": {},
   "source": [
    "#### -> 4) Apply EDA, regression, and plots to cross-section of dataset for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab7761-d4c0-4908-a4ab-286375f96e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe for 165 countries in 2018\n",
    "a18 = mi.loc[(mi['Year'] == '2018')] \n",
    "\n",
    "#show statistical information for cross secton df 'a18'\n",
    "a18.describe()\n",
    "\n",
    "sorted_a18 = a18.sort_values(by ='energy_per_capita')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fca33b-e912-455c-9556-15407e8adc8e",
   "metadata": {},
   "source": [
    "#### First, I want to see how good my model is at predicting Co2 levels using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c12795-f475-4649-9144-2057886f915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature and target arrays\n",
    "y = a18['ln_co2_per_capita'].values\n",
    "X = a18[['ln_energy_per_capita', 'ln_gdp_per_capita', 'ln_gpd_per_capita_squ']].values\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "tres = reg_all.fit(X_train,y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {:.2f}\".format(reg_all.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "print((reg_all.coef_))\n",
    "print(reg_all.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba622b7-00ae-4a3d-9713-306b86072138",
   "metadata": {},
   "source": [
    "#### Next, I want to apply my linear regression to the entire sample, save the predictions, and graph the predictions vs. GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f036327-b4fe-44ec-9a65-45eb576c9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature and target arrays\n",
    "y = a18['ln_co2_per_capita'].values\n",
    "X = a18[['ln_energy_per_capita', 'ln_gdp_per_capita', 'ln_gpd_per_capita_squ']].values\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the entire series\n",
    "tres = reg_all.fit(X,y)\n",
    "\n",
    "# Predict on the entire dataset: y_pred\n",
    "y_predall = reg_all.predict(X)\n",
    "\n",
    "#save the predictions as a df called 'prediction_df'\n",
    "prediction_df = pd.DataFrame(data=y_predall, index=None, columns=['predicted_co2']) \n",
    "\n",
    "#create a df called 'gdpk_df', which only includes gdp_per_capita\n",
    "gdpk_df = pd.DataFrame(data=a18, index=None, columns=['gdp_per_capita']) \n",
    "\n",
    "#reset the index for 'gdpk_df' \n",
    "gdpk_df=gdpk_df.reset_index()\n",
    "\n",
    "#merge the predictions df and gdpk_df using the index--call it 'df'\n",
    "df = gdpk_df.join(prediction_df)\n",
    "\n",
    "#print the first 5 rows of the new df 'df'\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d59cc4-aaee-4de0-84aa-af09e641d692",
   "metadata": {},
   "source": [
    "#### To visualize the Kuznets curve in my data, I graphed the predicted co2 emissions vs GDP per capita. We can start to visualize the statisitically significant quadratic relationship we established in the panel regression: that as countries grow and develop, they actually start to decrease their co2 emissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67eccde-d516-47fd-9cdc-1d76ce9d4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(x='gdp_per_capita', y='predicted_co2', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00dfb1-f05b-4443-99ae-5b2c79374d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59cde4-28ce-4e9d-abc8-3e72f556bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df for time-series graphs--reset the index from multi level to just date\n",
    "new = mi.reset_index()\n",
    "new.set_index('Date',drop=True,inplace=True)\n",
    "print(new.tail(2)) #show first 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba18f2-68a3-4055-859c-41c9dc150e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort 2018 df 'a18' by energy consumption per capita--default ascending\n",
    "sorted_a18 = a18.sort_values(by ='energy_per_capita')\n",
    "\n",
    "#Identify the TOP 6 energy consumers per capita in 2018\n",
    "print(sorted_a18.tail(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e3506-7b0b-4722-9208-74fd6fdf42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df for top 6 energy consumers in 2018 and plot the time series of co2 per capita from 2010-2018\n",
    "cd1 = 'ARE'\n",
    "cd2 = 'BHR'\n",
    "cd3 = 'TTO'\n",
    "cd4 = 'SGP'\n",
    "cd5 = 'QAT'\n",
    "cd6 = 'ISL'\n",
    "\n",
    "#create country specific df\n",
    "c1 = new[new['iso_code']== cd1]\n",
    "c2 = new[new['iso_code']== cd2]\n",
    "c3 = new[new['iso_code']== cd3]\n",
    "c4 = new[new['iso_code']== cd4]\n",
    "c5 = new[new['iso_code']== cd5]\n",
    "c6 = new[new['iso_code']== cd6]\n",
    "\n",
    "#plot each of the country time series\n",
    "with plt.style.context('seaborn'): #changed the style, just for fun\n",
    "    plt.plot(c1['co2_per_capita'], label = cd1 )\n",
    "    plt.plot(c2['co2_per_capita'], label = cd2)\n",
    "    plt.plot(c3['co2_per_capita'], label = cd3)\n",
    "    plt.plot(c4['co2_per_capita'], label = cd4)\n",
    "    plt.plot(c5['co2_per_capita'], label = cd5)\n",
    "    plt.plot(c6['co2_per_capita'], label = cd6)\n",
    "    plt.legend()\n",
    "    plt.title('Co2 per Capita for TOP 6 from 2010-2018')\n",
    "    plt.ylabel('Co2 per Capita (metric tons)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfe2c3-812d-4e62-82f6-3e99743bf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the lowest 6 energy consumers per capita in 2018\n",
    "print(sorted_a18.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6bdc2-9acc-480e-a6ce-8fafa61052df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df for lowest 6 energy consumers in 2018 and plot the time series of co2 per capita from 2010-2018\n",
    "cd1 = 'BDI'\n",
    "cd2 = 'CAF'\n",
    "cd3 = 'NER'\n",
    "cd4 = 'TCD'\n",
    "cd5 = 'COD'\n",
    "cd6 = 'RWA'\n",
    "\n",
    "#create country specific df using the country codes above so I only have to type them once\n",
    "c1 = new[new['iso_code']== cd1]\n",
    "c2 = new[new['iso_code']== cd2]\n",
    "c3 = new[new['iso_code']== cd3]\n",
    "c4 = new[new['iso_code']== cd4]\n",
    "c5 = new[new['iso_code']== cd5]\n",
    "c6 = new[new['iso_code']== cd6]\n",
    "\n",
    "#plot the time seris of co2 emissions for the lower 6 energy users in 2018\n",
    "with plt.style.context('seaborn'): #changed the style, just for fun\n",
    "    plt.plot(c1['co2_per_capita'], label = cd1 )\n",
    "    plt.plot(c2['co2_per_capita'], label = cd2)\n",
    "    plt.plot(c3['co2_per_capita'], label = cd3)\n",
    "    plt.plot(c4['co2_per_capita'], label = cd4)\n",
    "    plt.plot(c5['co2_per_capita'], label = cd5)\n",
    "    plt.plot(c6['co2_per_capita'], label = cd6)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('Co2 per Capita for LOW 6 from 2010-2018')\n",
    "    plt.ylabel('Co2 per Capita (metric tons)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c874a-328e-4081-bc59-3f53c0a50f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split Burunid data from 2010-2018 into two parts\n",
    "first = c1[c1['Year'] <= '2014']\n",
    "second = c1[c1['Year'] > '2014']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7ab81-9d7b-410c-9e0a-f24c726ff9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct a T test to see if the means of two samples are the same--Null: sample1 = sample2\n",
    "stats.ttest_ind(first['co2_per_capita'], second['co2_per_capita'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aedcde-0b1d-4645-8da2-97c5c9226010",
   "metadata": {},
   "source": [
    "###### ^fail to reject at the 0.5 level, indicating the two series are not statisically differnt from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706ee1a-61d4-4cc8-ad6f-b20f7796918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see how many countreis are in my datset\n",
    "print(new.groupby('iso_code').ngroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ccd92d-51cb-4d0b-8def-cec580dad205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the coutry codes keys\n",
    "print(new.groupby('iso_code').groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121fb60a-2070-4e54-a099-ba0302f1b39a",
   "metadata": {},
   "source": [
    "#### Peform a test using groupby to see if the co2 per capita are equivalent in usa and canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78f157-60cc-418b-a204-1e841f999aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the values of co2 emission per capita for the United States and canada using groupby\n",
    "usa = new.groupby('iso_code').get_group('USA')['co2_per_capita']\n",
    "can = new.groupby('iso_code').get_group('CAN')['co2_per_capita']\n",
    "\n",
    "#test the null that the two series are equal usa=can\n",
    "stats.ttest_ind(usa, can)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696f14c-0439-44ff-90e0-4e7dee5fe2ec",
   "metadata": {},
   "source": [
    "###### ^reject the null at  the 0.05 level, conclude that the two series are statistically differnt from one another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18255843-11af-4c18-8841-14c157b7b2da",
   "metadata": {},
   "source": [
    "#### Use the KNeighborsClassifier to Perform a test to see if I gdp and energy consumption can predict being above the average c02 emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d78509-b34d-4fcf-b7a5-17f0a674ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the 2018 cross section data I calculated the mean co2 emissions\n",
    "print(a18['co2_per_capita'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911aa7d-3032-4b4f-bf67-17a272796a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a dummy variale for countries that are emitting above the average for all countries---1 if above 0 if below \n",
    "a18.loc[:,'Above'] = (a18.loc[:, 'co2_per_capita'] > 4.74).astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5503af-ae13-473c-8118-01d3a96456fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays\n",
    "y = a18['Above'].values\n",
    "X = a18[['ln_energy_per_capita', 'ln_gdp_per_capita']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67b16f-9d01-4028-9665-8f1a3585bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-NN classifier with 2 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X,y)\n",
    "\n",
    "# Predict the labels for the training data X\n",
    "y_pred = knn.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9cd52-f901-4b39-9fe4-7f316b48fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percent of countries above the average Co2 emission per capita: ' , np.mean(y)*100, '%')\n",
    "print('Percent of countries predicted to be above the average Co2 emission per capita: ' , np.mean(y_pred)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f291d1-7cd1-48f4-9c94-86a081bec282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating arrays\n",
    "y = a18['Above'].values\n",
    "X = a18[['ln_energy_per_capita', 'ln_gdp_per_capita']].values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Create a k-NN classifier with 3 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Predict using the classifier\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('accuracy')\n",
    "print(\"Accuracy: {:.2f}\".format(knn.score(X_test, y_test)))\n",
    "print('-----------------------------------')\n",
    "#print the confusion matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print('upper left: true positive, lower left: false positive, upper right: false negative, bottom right: true negative')\n",
    "print('------------------------------------')\n",
    "print('classification report')\n",
    "print('------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f77dc-409f-483e-92dc-9bd1dfc8cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322b32b-738f-4ff7-845a-5db21f32824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525af86-b50a-415f-a0b2-225b5665f9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f1c62-c47c-4097-a289-990cd3f9dc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8c455-a563-4786-8a55-331ddd684dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dcbec-ddd7-4a9d-b530-552db80bd6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f27b61-c548-4c4c-865b-8b4b1498f14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b927c-52c1-4fe9-866a-c8cbe0088023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9262d-0d88-42d0-ba54-c5003b9fce59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f37cd2-b2bf-4b71-bccb-1f266022bede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1b317-7e20-4c94-bbae-f8d5983af711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
